{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "@webio": {
      "lastCommId": null,
      "lastKernelId": null
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Augmentation,Generators,Architectures_2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Dky7_ZTBeYA",
        "colab_type": "code",
        "outputId": "e0dec94c-a367-4222-bf8e-05cd9ebc3882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIlPWGIwBVFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import albumentations as A\n",
        "from pathlib import Path\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import sklearn.metrics\n",
        "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
        "from matplotlib.font_manager import FontProperties\n",
        "prop = FontProperties()\n",
        "plt.style.use('seaborn-dark-palette')\n",
        "#prop.set_file('../data/kalpurush.ttf')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya5LLb04BVGB",
        "colab_type": "code",
        "outputId": "3317a44a-07b8-43b2-f7e1-0b5cf7685dc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from IPython.display import SVG\n",
        "from tensorflow.keras import backend as K\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzNNF2REBVGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D, AvgPool2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmFXI_CbBVGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataframe = pd.read_parquet('/content/drive/My Drive/Bengali Grapheme/data/train_labels.parquet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTxxWHQyB__f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataframe.drop(['image_id','grapheme_root','vowel_diacritic','consonant_diacritic'],axis=1).values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyxsyhtvCbJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = dataframe[['grapheme_root','vowel_diacritic','consonant_diacritic']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4hK5DFkCl4O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QjsLZmfJNub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = X/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJgpHrXlBVG7",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNpYvMdDBVG_",
        "colab_type": "text"
      },
      "source": [
        "## Generators /Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pBHi0seBVHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "del X_train, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "code_folding": [],
        "id": "68OLCjtzBVIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_alexnet():\n",
        "    \n",
        "    input_ = Input(shape=(64,64,1))\n",
        "    \n",
        "    conv1 = Conv2D(filters=96, kernel_size=(11, 11), strides=4, padding='valid', activation='relu')(input_)\n",
        "    maxpool1 = MaxPool2D(pool_size=(3, 3), strides=2, padding='valid')(conv1)\n",
        "    bn1 = BatchNormalization()(maxpool1)\n",
        "    \n",
        "    conv2 = Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu')(bn1)\n",
        "    maxpool2 = MaxPool2D(pool_size=(3, 3), strides=2, padding='valid')(conv2)\n",
        "    bn2 = BatchNormalization()(maxpool2)\n",
        "    \n",
        "    conv3 = Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(bn2)\n",
        "    drop1 = Dropout(0.5)(conv3)\n",
        "    conv4 = Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(drop1)\n",
        "    drop2 = Dropout(0.5)(conv4)\n",
        "    conv5 = Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(drop2)\n",
        "    \n",
        "    flat = Flatten()(conv5)\n",
        "    \n",
        "    dense_root_1 = Dense(4096,activation='relu')(flat)\n",
        "    dense_root_2 = Dense(4096,activation='relu')(dense_root_1)\n",
        "    dense_root_3 = Dense(1000,activation='relu')(dense_root_2)\n",
        "    output_root = Dense(168,activation='softmax',name='root')(dense_root_3)\n",
        "    \n",
        "    dense_vowel_1 = Dense(800,activation='relu')(flat)\n",
        "    dense_vowel_2 = Dense(600,activation='relu')(dense_vowel_1)\n",
        "    dense_vowel_3 = Dense(100,activation='relu')(dense_vowel_2)\n",
        "    output_vowel = Dense(11,activation='softmax',name='vowel')(dense_vowel_3)\n",
        "    \n",
        "    dense_consonant_1 = Dense(800,activation='relu')(flat)\n",
        "    dense_consonant_2 = Dense(600,activation='relu')(dense_consonant_1)\n",
        "    dense_consonant_3 = Dense(100,activation='relu')(dense_consonant_2)\n",
        "    output_consonant = Dense(7,activation='softmax',name='consonant')(dense_consonant_3)\n",
        "    \n",
        "    model = keras.Model(inputs=[input_],outputs=[output_root,output_vowel,output_consonant])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwHEZRzuBVIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.clear_session()\n",
        "model_alexnet = model_alexnet()\n",
        "#keras.utils.plot_model(model_alexnet, '../results/alexnet.png', expand_nested=True, show_shapes=True);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEk_f1kQBVIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_alexnet.compile(loss = [keras.losses.sparse_categorical_crossentropy,\n",
        "                              keras.losses.sparse_categorical_crossentropy,\n",
        "                              keras.losses.sparse_categorical_crossentropy],\n",
        "              optimizer = 'Adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy5E61iyBVI5",
        "colab_type": "code",
        "outputId": "5a04c681-fd60-4a28-9993-a4759774d794",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history_alexnet = model_alexnet.fit(x_train.reshape(-1,64,64,1),\n",
        "                                    (y_train['grapheme_root'].values, y_train['vowel_diacritic'].values,\n",
        "                                     y_train['consonant_diacritic'].values), \n",
        "                                    validation_data = (x_valid.reshape(-1,64,64,1), (y_valid['grapheme_root'].values, y_valid['vowel_diacritic'].values,\n",
        "                                     y_valid['consonant_diacritic'].values)\n",
        "                                    batch_size=30, epochs=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200840 samples\n",
            "Epoch 1/30\n",
            "200840/200840 [==============================] - 78s 389us/sample - loss: 3.4582 - root_loss: 2.4689 - vowel_loss: 0.5642 - consonant_loss: 0.4250 - root_accuracy: 0.3204 - vowel_accuracy: 0.8067 - consonant_accuracy: 0.8558\n",
            "Epoch 2/30\n",
            "200840/200840 [==============================] - 79s 392us/sample - loss: 2.8346 - root_loss: 1.9887 - vowel_loss: 0.4875 - consonant_loss: 0.3585 - root_accuracy: 0.4387 - vowel_accuracy: 0.8348 - consonant_accuracy: 0.8789\n",
            "Epoch 3/30\n",
            "200840/200840 [==============================] - 78s 388us/sample - loss: 2.4761 - root_loss: 1.7178 - vowel_loss: 0.4372 - consonant_loss: 0.3211 - root_accuracy: 0.5136 - vowel_accuracy: 0.8542 - consonant_accuracy: 0.8919\n",
            "Epoch 4/30\n",
            "200840/200840 [==============================] - 78s 388us/sample - loss: 2.2429 - root_loss: 1.5439 - vowel_loss: 0.4031 - consonant_loss: 0.2960 - root_accuracy: 0.5602 - vowel_accuracy: 0.8662 - consonant_accuracy: 0.9011\n",
            "Epoch 5/30\n",
            "200840/200840 [==============================] - 79s 391us/sample - loss: 2.0486 - root_loss: 1.4004 - vowel_loss: 0.3757 - consonant_loss: 0.2724 - root_accuracy: 0.5991 - vowel_accuracy: 0.8751 - consonant_accuracy: 0.9097\n",
            "Epoch 6/30\n",
            "200840/200840 [==============================] - 79s 394us/sample - loss: 1.9070 - root_loss: 1.3002 - vowel_loss: 0.3526 - consonant_loss: 0.2541 - root_accuracy: 0.6279 - vowel_accuracy: 0.8838 - consonant_accuracy: 0.9153\n",
            "Epoch 7/30\n",
            "200840/200840 [==============================] - 79s 392us/sample - loss: 1.8157 - root_loss: 1.2321 - vowel_loss: 0.3396 - consonant_loss: 0.2440 - root_accuracy: 0.6465 - vowel_accuracy: 0.8881 - consonant_accuracy: 0.9189\n",
            "Epoch 8/30\n",
            "200840/200840 [==============================] - 81s 405us/sample - loss: 1.7374 - root_loss: 1.1799 - vowel_loss: 0.3247 - consonant_loss: 0.2328 - root_accuracy: 0.6609 - vowel_accuracy: 0.8931 - consonant_accuracy: 0.9235\n",
            "Epoch 9/30\n",
            "200840/200840 [==============================] - 84s 417us/sample - loss: 1.6743 - root_loss: 1.1377 - vowel_loss: 0.3122 - consonant_loss: 0.2244 - root_accuracy: 0.6749 - vowel_accuracy: 0.8979 - consonant_accuracy: 0.9260\n",
            "Epoch 10/30\n",
            "200840/200840 [==============================] - 84s 419us/sample - loss: 1.6268 - root_loss: 1.1015 - vowel_loss: 0.3062 - consonant_loss: 0.2191 - root_accuracy: 0.6854 - vowel_accuracy: 0.8999 - consonant_accuracy: 0.9282\n",
            "Epoch 11/30\n",
            "200840/200840 [==============================] - 83s 412us/sample - loss: 1.5816 - root_loss: 1.0717 - vowel_loss: 0.2992 - consonant_loss: 0.2106 - root_accuracy: 0.6935 - vowel_accuracy: 0.9024 - consonant_accuracy: 0.9308\n",
            "Epoch 12/30\n",
            "200840/200840 [==============================] - 82s 406us/sample - loss: 1.5343 - root_loss: 1.0386 - vowel_loss: 0.2892 - consonant_loss: 0.2065 - root_accuracy: 0.7017 - vowel_accuracy: 0.9062 - consonant_accuracy: 0.9323\n",
            "Epoch 13/30\n",
            "200840/200840 [==============================] - 79s 393us/sample - loss: 1.5014 - root_loss: 1.0173 - vowel_loss: 0.2836 - consonant_loss: 0.2004 - root_accuracy: 0.7093 - vowel_accuracy: 0.9082 - consonant_accuracy: 0.9352\n",
            "Epoch 14/30\n",
            "200840/200840 [==============================] - 79s 392us/sample - loss: 1.4588 - root_loss: 0.9898 - vowel_loss: 0.2760 - consonant_loss: 0.1931 - root_accuracy: 0.7165 - vowel_accuracy: 0.9108 - consonant_accuracy: 0.9374\n",
            "Epoch 15/30\n",
            "200840/200840 [==============================] - 78s 389us/sample - loss: 1.4367 - root_loss: 0.9734 - vowel_loss: 0.2721 - consonant_loss: 0.1912 - root_accuracy: 0.7214 - vowel_accuracy: 0.9126 - consonant_accuracy: 0.9385\n",
            "Epoch 16/30\n",
            "200840/200840 [==============================] - 78s 389us/sample - loss: 1.4239 - root_loss: 0.9626 - vowel_loss: 0.2695 - consonant_loss: 0.1919 - root_accuracy: 0.7250 - vowel_accuracy: 0.9138 - consonant_accuracy: 0.9392\n",
            "Epoch 17/30\n",
            "200840/200840 [==============================] - 78s 390us/sample - loss: 1.4019 - root_loss: 0.9517 - vowel_loss: 0.2654 - consonant_loss: 0.1848 - root_accuracy: 0.7288 - vowel_accuracy: 0.9152 - consonant_accuracy: 0.9411\n",
            "Epoch 18/30\n",
            "200840/200840 [==============================] - 79s 393us/sample - loss: 1.3788 - root_loss: 0.9366 - vowel_loss: 0.2618 - consonant_loss: 0.1804 - root_accuracy: 0.7334 - vowel_accuracy: 0.9166 - consonant_accuracy: 0.9419\n",
            "Epoch 19/30\n",
            "200840/200840 [==============================] - 78s 388us/sample - loss: 1.3725 - root_loss: 0.9277 - vowel_loss: 0.2638 - consonant_loss: 0.1810 - root_accuracy: 0.7370 - vowel_accuracy: 0.9160 - consonant_accuracy: 0.9428\n",
            "Epoch 20/30\n",
            "200840/200840 [==============================] - 78s 390us/sample - loss: 1.3357 - root_loss: 0.9046 - vowel_loss: 0.2554 - consonant_loss: 0.1757 - root_accuracy: 0.7421 - vowel_accuracy: 0.9187 - consonant_accuracy: 0.9437\n",
            "Epoch 21/30\n",
            "200840/200840 [==============================] - 78s 389us/sample - loss: 1.3705 - root_loss: 0.9260 - vowel_loss: 0.2626 - consonant_loss: 0.1819 - root_accuracy: 0.7370 - vowel_accuracy: 0.9168 - consonant_accuracy: 0.9424\n",
            "Epoch 22/30\n",
            "200840/200840 [==============================] - 79s 393us/sample - loss: 1.2729 - root_loss: 0.8613 - vowel_loss: 0.2434 - consonant_loss: 0.1682 - root_accuracy: 0.7534 - vowel_accuracy: 0.9226 - consonant_accuracy: 0.9466\n",
            "Epoch 23/30\n",
            "200840/200840 [==============================] - 79s 392us/sample - loss: 1.2721 - root_loss: 0.8595 - vowel_loss: 0.2436 - consonant_loss: 0.1690 - root_accuracy: 0.7549 - vowel_accuracy: 0.9233 - consonant_accuracy: 0.9457\n",
            "Epoch 24/30\n",
            "200840/200840 [==============================] - 79s 391us/sample - loss: 1.2759 - root_loss: 0.8603 - vowel_loss: 0.2454 - consonant_loss: 0.1701 - root_accuracy: 0.7563 - vowel_accuracy: 0.9235 - consonant_accuracy: 0.9465\n",
            "Epoch 25/30\n",
            "200840/200840 [==============================] - 79s 392us/sample - loss: 1.2553 - root_loss: 0.8509 - vowel_loss: 0.2397 - consonant_loss: 0.1646 - root_accuracy: 0.7575 - vowel_accuracy: 0.9247 - consonant_accuracy: 0.9483\n",
            "Epoch 26/30\n",
            "200840/200840 [==============================] - 79s 393us/sample - loss: 1.2352 - root_loss: 0.8375 - vowel_loss: 0.2366 - consonant_loss: 0.1611 - root_accuracy: 0.7625 - vowel_accuracy: 0.9256 - consonant_accuracy: 0.9493\n",
            "Epoch 27/30\n",
            "200840/200840 [==============================] - 79s 392us/sample - loss: 1.2407 - root_loss: 0.8372 - vowel_loss: 0.2397 - consonant_loss: 0.1638 - root_accuracy: 0.7623 - vowel_accuracy: 0.9248 - consonant_accuracy: 0.9490\n",
            "Epoch 28/30\n",
            "200840/200840 [==============================] - 79s 392us/sample - loss: 1.2468 - root_loss: 0.8397 - vowel_loss: 0.2407 - consonant_loss: 0.1664 - root_accuracy: 0.7623 - vowel_accuracy: 0.9251 - consonant_accuracy: 0.9484\n",
            "Epoch 29/30\n",
            "200840/200840 [==============================] - 79s 392us/sample - loss: 1.2660 - root_loss: 0.8562 - vowel_loss: 0.2434 - consonant_loss: 0.1664 - root_accuracy: 0.7600 - vowel_accuracy: 0.9249 - consonant_accuracy: 0.9478\n",
            "Epoch 30/30\n",
            "200840/200840 [==============================] - 79s 395us/sample - loss: 1.2204 - root_loss: 0.8238 - vowel_loss: 0.2382 - consonant_loss: 0.1584 - root_accuracy: 0.7688 - vowel_accuracy: 0.9266 - consonant_accuracy: 0.9498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yl0INdBgBVI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}