{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import albumentations as A\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
    "from matplotlib.font_manager import FontProperties\n",
    "prop = FontProperties()\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "prop.set_file('../data/kalpurush.ttf')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from IPython.display import SVG\n",
    "from tensorflow.keras import backend as K\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, AvgPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/sayan/Documents/Bengali_Grapheme/data/train.csv')\n",
    "strs = train_df['image_id'].values\n",
    "strs = [string+'_f.png' for string in strs]\n",
    "train_df.drop(['image_id'],axis=1,inplace=True)\n",
    "train_df['image_id'] = strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = pd.read_csv('/home/sayan/Documents/Bengali_Grapheme/data/class_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     39
    ]
   },
   "outputs": [],
   "source": [
    "def apply_augmentation(image):\n",
    "    augmentation_pipeline = A.Compose(\n",
    "        [\n",
    "            A.OneOf(\n",
    "                [\n",
    "                    # apply one of transforms to 50% of images\n",
    "                    A.RandomContrast(), # apply random contrast\n",
    "                    A.RandomGamma(), # apply random gamma\n",
    "                    A.RandomBrightness(), # apply random brightness\n",
    "                ],\n",
    "                p = 0.5\n",
    "            ),\n",
    "            A.OneOf(\n",
    "                [\n",
    "                    # apply one of transforms to 50% images\n",
    "                    A.ElasticTransform(alpha = 120,sigma = 120 * 0.05,alpha_affine = 120 * 0.03),\n",
    "                    A.GridDistortion(),\n",
    "                    A.OpticalDistortion(distort_limit = 2,shift_limit = 0.5),\n",
    "                    A.ShiftScaleRotate()\n",
    "                ],\n",
    "                p = 0.5\n",
    "            ),\n",
    "            A.OneOf(\n",
    "                [\n",
    "                    # apply one of transforms to 50% images\n",
    "                    A.GaussianBlur(alpha = 120,sigma = 120 * 0.05,alpha_affine = 120 * 0.03),\n",
    "                    A.GridDistortion(),\n",
    "                    A.OpticalDistortion(distort_limit = 2,shift_limit = 0.5),\n",
    "                    \n",
    "                    \n",
    "                ],\n",
    "                p = 0.5\n",
    "            )\n",
    "        ],\n",
    "        p = 0.5\n",
    "    )\n",
    "    images_aug = augmentation_pipeline(image = image)['image']\n",
    "    return images_aug\n",
    "\n",
    "def image_scale(image):\n",
    "    augmentation_pipeline = A.Resize(224,224,always_apply=True)\n",
    "    images_aug = augmentation_pipeline(image = image)['image']\n",
    "    \n",
    "    return images_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def modified_recall(y_true, y_pred):\n",
    "    \n",
    "    scores = []\n",
    "    for component in ['grapheme_root', 'consonant_diacritic', 'vowel_diacritic']:\n",
    "        y_true_subset = solution[solution[component] == component]['target'].values\n",
    "        y_pred_subset = submission[submission[component] == component]['target'].values\n",
    "        scores.append(sklearn.metrics.recall_score(\n",
    "            y_true_subset, y_pred_subset, average='macro'))\n",
    "    \n",
    "    final_score = np.average(scores, weights=[2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_toy_processed_images = '/home/sayan/Documents/Bengali_Grapheme/images/toy_processed_images'\n",
    "train_df_sample = pd.DataFrame()\n",
    "for (directory, _ , image_names) in os.walk(datadir_toy_processed_images):\n",
    "        train_df_sample = train_df[train_df['image_id'].isin(image_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df_1, valid_df_1 = train_test_split(train_df_sample, random_state=42,\n",
    "                                          stratify=train_df_sample[['grapheme_root',\n",
    "                                                                    'vowel_diacritic',\n",
    "                                                                    'consonant_diacritic']])\n",
    "\n",
    "#train_df_1, valid_df_1 = train_test_split(train_df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_image_generator(scale_flag):\n",
    "    \n",
    "    if scale_flag:\n",
    "        train_im_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255, \n",
    "                                                                             preprocessing_function = image_scale)\n",
    "        valid_im_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
    "                                                                             preprocessing_function = image_scale)\n",
    "        train_gen_image = train_im_generator.flow_from_dataframe(train_df_1,\n",
    "                                                   directory='/home/sayan/Documents/Bengali_Grapheme/images/toy_processed_images',\n",
    "                                                   x_col='image_id',\n",
    "                                                   y_col=['grapheme_root','vowel_diacritic','consonant_diacritic'],\n",
    "                                                   target_size = (224,224),\n",
    "                                                   class_mode = 'multi_output',\n",
    "                                                   #color_mode = 'grayscale',\n",
    "                                                   shuffle=False, \n",
    "                                                   batch_size = 10,\n",
    "                                                   seed=42)\n",
    "        valid_gen_image = valid_im_generator.flow_from_dataframe(valid_df_1,\n",
    "                                                   directory='/home/sayan/Documents/Bengali_Grapheme/images/toy_processed_images',\n",
    "                                                   x_col='image_id',\n",
    "                                                   y_col=['grapheme_root','vowel_diacritic','consonant_diacritic'],\n",
    "                                                   target_size = (224,224),\n",
    "                                                   class_mode = 'multi_output',\n",
    "                                                   #color_mode = 'grayscale',\n",
    "                                                   shuffle=False, \n",
    "                                                   batch_size = 10,\n",
    "                                                   seed=42)\n",
    "        \n",
    "    else:\n",
    "        train_im_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "        valid_im_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "        \n",
    "        train_gen_image = train_im_generator.flow_from_dataframe(train_df_1,\n",
    "                                                   directory='/home/sayan/Documents/Bengali_Grapheme/images/toy_processed_images',\n",
    "                                                   x_col='image_id',\n",
    "                                                   y_col=['grapheme_root','vowel_diacritic','consonant_diacritic'],\n",
    "                                                   target_size = (64,64),\n",
    "                                                   class_mode = 'multi_output',\n",
    "                                                   color_mode = 'grayscale',\n",
    "                                                   shuffle=False, \n",
    "                                                   batch_size = 10,\n",
    "                                                   seed=42)\n",
    "        valid_gen_image = valid_im_generator.flow_from_dataframe(valid_df_1,\n",
    "                                                   directory='/home/sayan/Documents/Bengali_Grapheme/images/toy_processed_images',\n",
    "                                                   x_col='image_id',\n",
    "                                                   y_col=['grapheme_root','vowel_diacritic','consonant_diacritic'],\n",
    "                                                   target_size = (64,64),\n",
    "                                                   class_mode = 'multi_output',\n",
    "                                                   color_mode = 'grayscale',\n",
    "                                                   shuffle=False, \n",
    "                                                   batch_size = 10,\n",
    "                                                   seed=42)\n",
    "        \n",
    "    return (train_gen_image, valid_gen_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def oneHotEncode_outputs(gen_image):\n",
    "    while True:\n",
    "        output = next(gen_image)\n",
    "        img = output[0]\n",
    "        labels = output[1]\n",
    "        #grapheme_label = np.zeros(168)\n",
    "        #vowel_label = np.zeros(11)\n",
    "        #consonant_label = np.zeros(7)\n",
    "        for i in range(3):\n",
    "            if i == 0:\n",
    "                a = labels[i]\n",
    "                b = np.zeros((a.size, 168))\n",
    "                b[np.arange(a.size),a] = 1\n",
    "                labels[i] = b\n",
    "            elif i == 1:\n",
    "                a = labels[i]\n",
    "                b = np.zeros((a.size, 11))\n",
    "                b[np.arange(a.size),a] = 1\n",
    "                labels[i] = b\n",
    "            else:\n",
    "                a = labels[i]\n",
    "                b = np.zeros((a.size, 7))\n",
    "                b[np.arange(a.size),a] = 1\n",
    "                labels[i] = b\n",
    "        yield (img, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if generator labels are accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def image_from_char(char):\n",
    "    HEIGHT = 236\n",
    "    WIDTH = 236\n",
    "    image = Image.new('RGB', (WIDTH, HEIGHT))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    myfont = ImageFont.truetype('../data/kalpurush.ttf', 120)\n",
    "    w, h = draw.textsize(char, font=myfont)\n",
    "    draw.text(((WIDTH - w) / 2,(HEIGHT - h) / 3), char, font=myfont)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def check_generators(gen_image, train_df,fname,class_map=class_map):\n",
    "    \n",
    "    output = next(gen_image)\n",
    "    fig, axs = plt.subplots(gen_image.batch_size,4, figsize=(64, 64))\n",
    "    gs1 = gridspec.GridSpec(gen_image.batch_size, 4)\n",
    "    \n",
    "    gs1.update(wspace=0.025, hspace=0.05)\n",
    "    plt.subplots_adjust(wspace=-0.8, hspace=0.1)\n",
    "    images = output[0]\n",
    "    roots = output[1][0]\n",
    "    vowels = output[1][1]\n",
    "    consonants = output[1][2]\n",
    "    \n",
    "    for i in range(gen_image.batch_size): \n",
    "        image = images[i].reshape(64,64)\n",
    "        grapheme_root = roots[i]\n",
    "        vowel_diacritic = vowels[i]\n",
    "        consonant_diacritic = consonants[i]\n",
    "        vowel_label = class_map[(class_map['component_type'] == 'vowel_diacritic') \n",
    "                            & (class_map['label'] == vowel_diacritic)]['component'].values[0]\n",
    "        consonant_label = class_map[(class_map['component_type'] == 'consonant_diacritic') \n",
    "                            & (class_map['label'] == consonant_diacritic)]['component'].values[0]\n",
    "        root_label = class_map[(class_map['component_type'] == 'grapheme_root') \n",
    "                            & (class_map['label'] == grapheme_root)]['component'].values[0]\n",
    "        \n",
    "        axs[i,0].imshow(image,cmap='Greys')\n",
    "        axs[i,0].axis('off')\n",
    "        axs[i,0].set_aspect('equal')\n",
    "        axs[i,1].imshow(image_from_char(root_label), cmap='Greys')\n",
    "        axs[i,1].axis('off')\n",
    "        axs[i,1].set_aspect('equal')\n",
    "        axs[i,2].imshow(image_from_char(vowel_label), cmap='Greys')\n",
    "        axs[i,2].axis('off')\n",
    "        axs[i,2].set_aspect('equal')\n",
    "        axs[i,3].imshow(image_from_char(consonant_label), cmap='Greys')\n",
    "        axs[i,3].axis('off')\n",
    "        axs[i,3].set_aspect('equal')\n",
    "        \n",
    "    fig.savefig('../results/'+fname+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_generators(train_gen_image,train_df_1,'full_processed_train_images',class_map);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CyclicLR(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self,base_lr, max_lr, step_size, base_m, max_m, cyclical_momentum):\n",
    " \n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.base_m = base_m\n",
    "        self.max_m = max_m\n",
    "        self.cyclical_momentum = cyclical_momentum\n",
    "        self.step_size = step_size\n",
    "        \n",
    "        self.clr_iterations = 0.\n",
    "        self.cm_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "        \n",
    "    def clr(self):\n",
    "        \n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        \n",
    "        if cycle == 2:\n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)          \n",
    "            return self.base_lr-(self.base_lr-self.base_lr/100)*np.maximum(0,(1-x))\n",
    "        \n",
    "        else:\n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0,(1-x))\n",
    "    \n",
    "    def cm(self):\n",
    "        \n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        \n",
    "        if cycle == 2:\n",
    "            \n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1) \n",
    "            return self.max_m\n",
    "        \n",
    "        else:\n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "            return self.max_m - (self.max_m-self.base_m)*np.maximum(0,(1-x))\n",
    "        \n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())\n",
    "            \n",
    "        if self.cyclical_momentum == True:\n",
    "            if self.clr_iterations == 0:\n",
    "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
    "            else:\n",
    "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
    "            \n",
    "            \n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "        \n",
    "        if self.cyclical_momentum == True:\n",
    "            self.history.setdefault('momentum', []).append(K.get_value(self.model.optimizer.momentum))\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "        \n",
    "        if self.cyclical_momentum == True:\n",
    "            K.set_value(self.model.optimizer.momentum, self.cm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_callbacks(chkpoint_name, log_name, lr_monitor):\n",
    "    \n",
    "    checkpoint_cb = keras.callbacks.ModelCheckpoint('../checkpoints/'+chkpoint_name,save_best_only=True)\n",
    "    \n",
    "    early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "    reduceLR_cb = keras.callbacks.ReduceLROnPlateau(monitor=lr_monitor, factor=0.2,\n",
    "                                                    patience=5, min_lr=0.001)\n",
    "    root_logdir = '/home/sayan/Documents/Bengali_Grapheme/logs/'\n",
    "    \n",
    "    batch_size = train_gen_image.batch_size\n",
    "    epochs = 10\n",
    "    max_lr = 0.5\n",
    "    base_lr = max_lr/10\n",
    "    max_m = 0.98\n",
    "    base_m = 0.85\n",
    "\n",
    "    cyclical_momentum = True\n",
    "    augment = True\n",
    "    cycles = 2.35\n",
    "    \n",
    "    def get_run_logdir(name):\n",
    "        import time\n",
    "        run_id = time.strftime(name)\n",
    "        return os.path.join(root_logdir,run_id)\n",
    "\n",
    "    run_logdir = get_run_logdir(log_name+'-run_%Y_%m_%d-%H_%M_%S')\n",
    "\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "    iterations = round(len(train_df)/batch_size*epochs)\n",
    "    iterations = list(range(0,iterations+1))\n",
    "    step_size = len(iterations)/(cycles)\n",
    "    cyclicLR_cb =  CyclicLR(base_lr=base_lr,\n",
    "                            max_lr=max_lr,\n",
    "                            step_size=step_size,\n",
    "                            max_m=max_m,\n",
    "                            base_m=base_m,\n",
    "                            cyclical_momentum=cyclical_momentum)\n",
    "    \n",
    "    return [checkpoint_cb, reduceLR_cb, tensorboard_cb, early_stopping_cb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def model_vanilla():\n",
    "    \n",
    "    input_ = Input(shape=(64,64,1))\n",
    "    conv1 = Conv2D(filters=6, kernel_size=(3, 3), activation='relu')(input_)\n",
    "    avgpool1 = AvgPool2D()(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(avgpool1)\n",
    "    avgpool2 = AvgPool2D()(conv2)\n",
    "\n",
    "    flat = Flatten()(avgpool2)\n",
    "    \n",
    "    dense_root_1 = Dense(2000,activation='relu')(flat)\n",
    "    dense_root_2 = Dense(1500,activation='relu')(dense_root_1)\n",
    "    dense_root_3 = Dense(1000,activation='relu')(dense_root_2)\n",
    "    dense_root_4 = Dense(800,activation='relu')(dense_root_3)\n",
    "    dense_root_5 = Dense(250,activation='relu')(dense_root_4)\n",
    "    output_root = Dense(168,activation='softmax',name='root')(dense_root_4)\n",
    "    \n",
    "    dense_vowel_1 = Dense(800,activation='relu')(flat)\n",
    "    dense_vowel_2 = Dense(600,activation='relu')(dense_vowel_1)\n",
    "    dense_vowel_3 = Dense(100,activation='relu')(dense_vowel_2)\n",
    "    output_vowel = Dense(11,activation='softmax',name='vowel')(dense_vowel_3)\n",
    "    \n",
    "    dense_consonant_1 = Dense(800,activation='relu')(flat)\n",
    "    dense_consonant_2 = Dense(600,activation='relu')(dense_consonant_1)\n",
    "    dense_consonant_3 = Dense(100,activation='relu')(dense_consonant_2)\n",
    "    output_consonant = Dense(7,activation='softmax',name='consonant')(dense_consonant_3)\n",
    "    \n",
    "    model = keras.Model(inputs=[input_],outputs=[output_root,output_vowel,output_consonant])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model_vanilla = model_vanilla()\n",
    "keras.utils.plot_model(model_vanilla, '../results/vanilla_model.png', expand_nested=True, show_shapes=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.05),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "(train_gen_image, valid_gen_image) = get_image_generator(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vanilla = model_vanilla.fit(train_gen_image,\n",
    "                                    validation_data=valid_gen_image,\n",
    "                                    epochs = 5,callbacks=get_callbacks('vanilla.h5',\n",
    "                                                                                 'vanilla.h5','vowel_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla.save('../models/vanilla.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alex Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def model_alexnet():\n",
    "    \n",
    "    input_ = Input(shape=(64,64,1))\n",
    "    \n",
    "    conv1 = Conv2D(filters=96, kernel_size=(11, 11), strides=4, padding='valid', activation='relu')(input_)\n",
    "    maxpool1 = MaxPool2D(pool_size=(3, 3), strides=2, padding='valid')(conv1)\n",
    "    bn1 = BatchNormalization()(maxpool1)\n",
    "    \n",
    "    conv2 = Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu')(bn1)\n",
    "    maxpool2 = MaxPool2D(pool_size=(3, 3), strides=2, padding='valid')(conv2)\n",
    "    bn2 = BatchNormalization()(maxpool2)\n",
    "    \n",
    "    conv3 = Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(bn2)\n",
    "    drop1 = Dropout(0.5)(conv3)\n",
    "    conv4 = Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(drop1)\n",
    "    drop2 = Dropout(0.5)(conv4)\n",
    "    conv5 = Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(drop2)\n",
    "    \n",
    "    flat = Flatten()(conv5)\n",
    "    \n",
    "    dense_root_1 = Dense(4096,activation='relu')(flat)\n",
    "    dense_root_2 = Dense(4096,activation='relu')(dense_root_1)\n",
    "    dense_root_3 = Dense(1000,activation='relu')(dense_root_2)\n",
    "    output_root = Dense(168,activation='softmax',name='root')(dense_root_3)\n",
    "    \n",
    "    dense_vowel_1 = Dense(800,activation='relu')(flat)\n",
    "    dense_vowel_2 = Dense(600,activation='relu')(dense_vowel_1)\n",
    "    dense_vowel_3 = Dense(100,activation='relu')(dense_vowel_2)\n",
    "    output_vowel = Dense(11,activation='softmax',name='vowel')(dense_vowel_3)\n",
    "    \n",
    "    dense_consonant_1 = Dense(800,activation='relu')(flat)\n",
    "    dense_consonant_2 = Dense(600,activation='relu')(dense_consonant_1)\n",
    "    dense_consonant_3 = Dense(100,activation='relu')(dense_consonant_2)\n",
    "    output_consonant = Dense(7,activation='softmax',name='consonant')(dense_consonant_3)\n",
    "    \n",
    "    model = keras.Model(inputs=[input_],outputs=[output_root,output_vowel,output_consonant])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model_alexnet = model_alexnet()\n",
    "keras.utils.plot_model(model_alexnet, '../results/alexnet.png', expand_nested=True, show_shapes=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alexnet.compile(loss = [keras.losses.sparse_categorical_crossentropy,\n",
    "                              keras.losses.sparse_categorical_crossentropy,\n",
    "                              keras.losses.sparse_categorical_crossentropy],\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.05),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "(train_gen_image, valid_gen_image) = get_image_generator(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_alexnet = model_alexnet.fit_generator(train_gen_image,\n",
    "                                    validation_data=valid_gen_image,\n",
    "                                    epochs = 50,callbacks=callbacks=get_callbacks('alexnet.h5',\n",
    "                                                                                  'alexnet.h5','vowel_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alexnet.save('../models/alexnet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def bengali_kaggle():\n",
    "    \n",
    "    input_ = Input(shape = (64, 64, 1))\n",
    "#    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu', input_shape=(137, 236, 1))(input_)\n",
    "#    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "#    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "#    model = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "#    model = BatchNormalization(momentum=0.15)(model)\n",
    "#    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "#    model = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "#    model = Dropout(rate=0.3)(model)\n",
    "    \n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu', input_shape=(64, 64, 1))(input_)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=0.3)(model)\n",
    "    \n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=0.3)(model)\n",
    "    \n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = MaxPool2D(pool_size=(2, 2))(model)\n",
    "    model = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\n",
    "    model = BatchNormalization(momentum=0.15)(model)\n",
    "    model = Dropout(rate=0.3)(model)\n",
    "    \n",
    "    model = Flatten()(model)\n",
    "    model = Dense(1024, activation = \"relu\")(model)\n",
    "    model = Dropout(rate=0.3)(model)\n",
    "    dense = Dense(512, activation = \"relu\")(model)\n",
    "    \n",
    "    head_root = Dense(168, activation = 'softmax',name='root')(dense)\n",
    "    head_vowel = Dense(11, activation = 'softmax',name='vowel')(dense)\n",
    "    head_consonant = Dense(7, activation = 'softmax',name='consonant')(dense)\n",
    "    \n",
    "    model = keras.Model(inputs=input_, outputs=[head_root, head_vowel, head_consonant])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model_kaggle = bengali_kaggle()\n",
    "keras.utils.plot_model(model_kaggle, '../results/bengali_kaggle.png', expand_nested=True, show_shapes=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kaggle.compile(loss = [keras.losses.sparse_categorical_crossentropy,\n",
    "                              keras.losses.sparse_categorical_crossentropy,\n",
    "                              keras.losses.sparse_categorical_crossentropy],\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.05),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "(train_gen_image, valid_gen_image) = get_image_generator(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "history_kaggle = model_kaggle.fit(train_gen_image,\n",
    "                                    validation_data=valid_gen_image,\n",
    "                                    epochs = 5,callbacks=get_callbacks('bengali_kaggle.h5',\n",
    "                                                                       'bengali_kaggle.h5','vowel_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kaggle.save('../models/bengali_kaggle.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "base_model_resnet = keras.applications.resnet_v2.ResNet152V2(weights='imagenet',\n",
    "                                                      include_top=False,\n",
    "                                                      input_shape= (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = keras.layers.GlobalAveragePooling2D()(base_model_resnet.output)\n",
    "head_root = (Dense(168, activation = 'softmax',name='root'))(model_resnet)\n",
    "head_vowel = Dense(11, activation = 'softmax',name='vowel')(model_resnet)\n",
    "head_consonant = Dense(7, activation = 'softmax',name='consonant')(model_resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet = keras.Model(inputs=base_model_resnet.input,outputs=[head_root, head_vowel, head_consonant])\n",
    "keras.utils.plot_model(model_resnet, '../results/resnet.png', expand_nested=True, show_shapes=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model_resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for layer in model_resnet.layers:\n",
    "    print(str(layer)+ ' ' +str(layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet.compile(loss = [keras.losses.sparse_categorical_crossentropy,\n",
    "                              keras.losses.sparse_categorical_crossentropy,\n",
    "                              keras.losses.sparse_categorical_crossentropy],\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.05),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "(train_gen_image, valid_gen_image) = get_image_generator(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_resnet = model_resnet.fit(train_gen_image,\n",
    "                                  validation_data=valid_gen_image,\n",
    "                                  epochs = 3,callbacks=get_callbacks('resnet50.h5','resnet50.h5','vowel_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet.save('../models/resnet50.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "base_model_vggnet = keras.applications.vgg16.VGG16(weights='imagenet',\n",
    "                                                      include_top=False,\n",
    "                                                      input_shape= (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vggnet = keras.layers.GlobalAveragePooling2D()(base_model_vggnet.output)\n",
    "head_root = (Dense(168, activation = 'softmax',name='root'))(model_vggnet)\n",
    "head_vowel = Dense(11, activation = 'softmax',name='vowel')(model_vggnet)\n",
    "head_consonant = Dense(7, activation = 'softmax',name='consonant')(model_vggnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vggnet = keras.Model(inputs=base_model_vggnet.input,outputs=[head_root, head_vowel, head_consonant])\n",
    "keras.utils.plot_model(model_vggnet, '../results/vggnet.png', expand_nested=True, show_shapes=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model_vggnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_vggnet.layers:\n",
    "    print(str(layer)+ ' ' +str(layer.trainable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vggnet.compile(loss = [keras.losses.sparse_categorical_crossentropy,\n",
    "                              keras.losses.sparse_categorical_crossentropy,\n",
    "                              keras.losses.sparse_categorical_crossentropy],\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.05),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "(train_gen_image, valid_gen_image) = get_image_generator(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_vggnet = model_vggnet.fit(train_gen_image,\n",
    "                                  validation_data=valid_gen_image,\n",
    "                                  epochs = 3,callbacks=get_callbacks('vggnet50.h5','vggnet50.h5','vowel_loss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vggnet.save('../models/vgg16.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "base_model_xception = keras.applications.xception.Xception(weights='imagenet',\n",
    "                                                      include_top=False,\n",
    "                                                      input_shape= (224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception = keras.layers.GlobalAveragePooling2D()(base_model_xception.output)\n",
    "head_root = (Dense(168, activation = 'softmax',name='root'))(model_xception)\n",
    "head_vowel = Dense(11, activation = 'softmax',name='vowel')(model_xception)\n",
    "head_consonant = Dense(7, activation = 'softmax',name='consonant')(model_xception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception = keras.Model(inputs=base_model_xception.input,outputs=[head_root, head_vowel, head_consonant])\n",
    "keras.utils.plot_model(model_xception, '../results/xception.png', expand_nested=True, show_shapes=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model_xception.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xception.compile(loss = [keras.losses.sparse_categorical_crossentropy,\n",
    "                              keras.losses.sparse_categorical_crossentropy,\n",
    "                              keras.losses.sparse_categorical_crossentropy],\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.05),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "(train_gen_image, valid_gen_image) = get_image_generator(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_xception = model_xception.fit(train_gen_image,\n",
    "                                  validation_data=valid_gen_image,\n",
    "                                  epochs = 3,callbacks=get_callbacks('xception.h5','xception.h5','vowel_loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
