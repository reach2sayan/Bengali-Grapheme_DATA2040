{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import albumentations as A\n",
    "from pathlib import Path\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import sklearn.metrics\n",
    "import PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\n",
    "from matplotlib.font_manager import FontProperties\n",
    "prop = FontProperties()\n",
    "plt.style.use('seaborn-dark-palette')\n",
    "prop.set_file('../data/kalpurush.ttf')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from IPython.display import SVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AvgPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/home/sayan/Documents/Bengali_Grapheme/data/train.csv')\n",
    "strs = train_df['image_id'].values\n",
    "strs = [string+'_f.png' for string in strs]\n",
    "train_df.drop(['image_id'],axis=1,inplace=True)\n",
    "train_df['image_id'] = strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_map = pd.read_csv('/home/sayan/Documents/Bengali_Grapheme/data/class_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def apply_augmentation(image):\n",
    "    augmentation_pipeline = A.Compose(\n",
    "        [\n",
    "            A.OneOf(\n",
    "                [\n",
    "                    # apply one of transforms to 50% of images\n",
    "                    A.RandomContrast(), # apply random contrast\n",
    "                    A.RandomGamma(), # apply random gamma\n",
    "                    A.RandomBrightness(), # apply random brightness\n",
    "                ],\n",
    "                p = 0.5\n",
    "            ),\n",
    "            A.OneOf(\n",
    "                [\n",
    "                    # apply one of transforms to 50% images\n",
    "                    A.ElasticTransform(alpha = 120,sigma = 120 * 0.05,alpha_affine = 120 * 0.03),\n",
    "                    A.GridDistortion(),\n",
    "                    A.OpticalDistortion(distort_limit = 2,shift_limit = 0.5),\n",
    "                ],\n",
    "                p = 0.5\n",
    "            )\n",
    "        ],\n",
    "        p = 0.5\n",
    "    )\n",
    "    images_aug = augmentation_pipeline(image = image)['image']\n",
    "    return images_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def modified_recall(y_true, y_pred):\n",
    "    \n",
    "    scores = []\n",
    "    for component in ['grapheme_root', 'consonant_diacritic', 'vowel_diacritic']:\n",
    "        y_true_subset = solution[solution[component] == component]['target'].values\n",
    "        y_pred_subset = submission[submission[component] == component]['target'].values\n",
    "        scores.append(sklearn.metrics.recall_score(\n",
    "            y_true_subset, y_pred_subset, average='macro'))\n",
    "    \n",
    "    final_score = np.average(scores, weights=[2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir_toy_processed_images = '/home/sayan/Documents/Bengali_Grapheme/images/toy_processed_images'\n",
    "train_df_sample = pd.DataFrame()\n",
    "for (directory, _ , image_names) in os.walk(datadir_toy_processed_images):\n",
    "        train_df_sample = train_df[train_df['image_id'].isin(image_names)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df_1, valid_df_1 = train_test_split(train_df_sample,stratify=train_df_sample[['grapheme_root',\n",
    "                                                                                'vowel_diacritic',\n",
    "                                                                                'consonant_diacritic']])\n",
    "\n",
    "#train_df_1, valid_df_1 = train_test_split(train_df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     5,
     16
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15063 validated image filenames.\n",
      "Found 5021 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_im_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
    "                                                               preprocessing_function=apply_augmentation)\n",
    "\n",
    "valid_im_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_gen_image = train_im_generator.flow_from_dataframe(train_df_1,\n",
    "                                                   directory='/home/sayan/Documents/Bengali_Grapheme/images/toy_processed_images',\n",
    "                                                   x_col='image_id',\n",
    "                                                   y_col=['grapheme_root','vowel_diacritic','consonant_diacritic'],\n",
    "                                                   target_size = (64,64),\n",
    "                                                   class_mode = 'multi_output',\n",
    "                                                   color_mode = 'grayscale',\n",
    "                                                   shuffle=False, \n",
    "                                                   batch_size = 10,\n",
    "                                                   seed=42)\n",
    "\n",
    "valid_gen_image = valid_im_generator.flow_from_dataframe(valid_df_1,\n",
    "                                                   directory='/home/sayan/Documents/Bengali_Grapheme/images/toy_processed_images',\n",
    "                                                   x_col='image_id',\n",
    "                                                   y_col=['grapheme_root','vowel_diacritic','consonant_diacritic'],\n",
    "                                                   target_size = (64,64),\n",
    "                                                   class_mode = 'multi_output',\n",
    "                                                   color_mode = 'grayscale',\n",
    "                                                   shuffle=False, \n",
    "                                                   batch_size = 10,\n",
    "                                                   seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def oneHotEncode_outputs(gen_image):\n",
    "    while True:\n",
    "        output = next(gen_image)\n",
    "        img = output[0]\n",
    "        labels = output[1]\n",
    "        #grapheme_label = np.zeros(168)\n",
    "        #vowel_label = np.zeros(11)\n",
    "        #consonant_label = np.zeros(7)\n",
    "        for i in range(3):\n",
    "            if i == 0:\n",
    "                a = labels[i]\n",
    "                b = np.zeros((a.size, 168))\n",
    "                b[np.arange(a.size),a] = 1\n",
    "                labels[i] = b\n",
    "            elif i == 1:\n",
    "                a = labels[i]\n",
    "                b = np.zeros((a.size, 11))\n",
    "                b[np.arange(a.size),a] = 1\n",
    "                labels[i] = b\n",
    "            else:\n",
    "                a = labels[i]\n",
    "                b = np.zeros((a.size, 7))\n",
    "                b[np.arange(a.size),a] = 1\n",
    "                labels[i] = b\n",
    "        yield (img, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if generator labels are accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def image_from_char(char):\n",
    "    HEIGHT = 236\n",
    "    WIDTH = 236\n",
    "    image = Image.new('RGB', (WIDTH, HEIGHT))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    myfont = ImageFont.truetype('../data/kalpurush.ttf', 120)\n",
    "    w, h = draw.textsize(char, font=myfont)\n",
    "    draw.text(((WIDTH - w) / 2,(HEIGHT - h) / 3), char, font=myfont)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def check_generators(gen_image, train_df,fname,class_map=class_map):\n",
    "    \n",
    "    output = next(gen_image)\n",
    "    fig, axs = plt.subplots(gen_image.batch_size,4, figsize=(64, 64))\n",
    "    gs1 = gridspec.GridSpec(gen_image.batch_size, 4)\n",
    "    \n",
    "    gs1.update(wspace=0.025, hspace=0.05)\n",
    "    plt.subplots_adjust(wspace=-0.8, hspace=0.1)\n",
    "    images = output[0]\n",
    "    roots = output[1][0]\n",
    "    vowels = output[1][1]\n",
    "    consonants = output[1][2]\n",
    "    \n",
    "    for i in range(gen_image.batch_size): \n",
    "        image = images[i].reshape(64,64)\n",
    "        grapheme_root = roots[i]\n",
    "        vowel_diacritic = vowels[i]\n",
    "        consonant_diacritic = consonants[i]\n",
    "        vowel_label = class_map[(class_map['component_type'] == 'vowel_diacritic') \n",
    "                            & (class_map['label'] == vowel_diacritic)]['component'].values[0]\n",
    "        consonant_label = class_map[(class_map['component_type'] == 'consonant_diacritic') \n",
    "                            & (class_map['label'] == consonant_diacritic)]['component'].values[0]\n",
    "        root_label = class_map[(class_map['component_type'] == 'grapheme_root') \n",
    "                            & (class_map['label'] == grapheme_root)]['component'].values[0]\n",
    "        \n",
    "        axs[i,0].imshow(image,cmap='Greys')\n",
    "        axs[i,0].axis('off')\n",
    "        axs[i,0].set_aspect('equal')\n",
    "        axs[i,1].imshow(image_from_char(root_label), cmap='Greys')\n",
    "        axs[i,1].axis('off')\n",
    "        axs[i,1].set_aspect('equal')\n",
    "        axs[i,2].imshow(image_from_char(vowel_label), cmap='Greys')\n",
    "        axs[i,2].axis('off')\n",
    "        axs[i,2].set_aspect('equal')\n",
    "        axs[i,3].imshow(image_from_char(consonant_label), cmap='Greys')\n",
    "        axs[i,3].axis('off')\n",
    "        axs[i,3].set_aspect('equal')\n",
    "        \n",
    "    fig.savefig('../results/'+fname+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_generators(valid_gen_image,valid_df_1,'validation_images',class_map);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class CyclicLR(keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self,base_lr, max_lr, step_size, base_m, max_m, cyclical_momentum):\n",
    " \n",
    "        self.base_lr = base_lr\n",
    "        self.max_lr = max_lr\n",
    "        self.base_m = base_m\n",
    "        self.max_m = max_m\n",
    "        self.cyclical_momentum = cyclical_momentum\n",
    "        self.step_size = step_size\n",
    "        \n",
    "        self.clr_iterations = 0.\n",
    "        self.cm_iterations = 0.\n",
    "        self.trn_iterations = 0.\n",
    "        self.history = {}\n",
    "        \n",
    "    def clr(self):\n",
    "        \n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        \n",
    "        if cycle == 2:\n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)          \n",
    "            return self.base_lr-(self.base_lr-self.base_lr/100)*np.maximum(0,(1-x))\n",
    "        \n",
    "        else:\n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "            return self.base_lr + (self.max_lr-self.base_lr)*np.maximum(0,(1-x))\n",
    "    \n",
    "    def cm(self):\n",
    "        \n",
    "        cycle = np.floor(1+self.clr_iterations/(2*self.step_size))\n",
    "        \n",
    "        if cycle == 2:\n",
    "            \n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1) \n",
    "            return self.max_m\n",
    "        \n",
    "        else:\n",
    "            x = np.abs(self.clr_iterations/self.step_size - 2*cycle + 1)\n",
    "            return self.max_m - (self.max_m-self.base_m)*np.maximum(0,(1-x))\n",
    "        \n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        logs = logs or {}\n",
    "\n",
    "        if self.clr_iterations == 0:\n",
    "            K.set_value(self.model.optimizer.lr, self.base_lr)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr, self.clr())\n",
    "            \n",
    "        if self.cyclical_momentum == True:\n",
    "            if self.clr_iterations == 0:\n",
    "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
    "            else:\n",
    "                K.set_value(self.model.optimizer.momentum, self.cm())\n",
    "            \n",
    "            \n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        \n",
    "        logs = logs or {}\n",
    "        self.trn_iterations += 1\n",
    "        self.clr_iterations += 1\n",
    "\n",
    "        self.history.setdefault('lr', []).append(K.get_value(self.model.optimizer.lr))\n",
    "        self.history.setdefault('iterations', []).append(self.trn_iterations)\n",
    "        \n",
    "        if self.cyclical_momentum == True:\n",
    "            self.history.setdefault('momentum', []).append(K.get_value(self.model.optimizer.momentum))\n",
    "\n",
    "        for k, v in logs.items():\n",
    "            self.history.setdefault(k, []).append(v)\n",
    "        \n",
    "        K.set_value(self.model.optimizer.lr, self.clr())\n",
    "        \n",
    "        if self.cyclical_momentum == True:\n",
    "            K.set_value(self.model.optimizer.momentum, self.cm())\n",
    "\n",
    "batch_size = train_gen_image.batch_size\n",
    "epochs = 10\n",
    "max_lr = 0.5\n",
    "base_lr = max_lr/10\n",
    "max_m = 0.98\n",
    "base_m = 0.85\n",
    "\n",
    "cyclical_momentum = True\n",
    "augment = True\n",
    "cycles = 2.35\n",
    "\n",
    "iterations = round(len(train_df)/batch_size*epochs)\n",
    "iterations = list(range(0,iterations+1))\n",
    "step_size = len(iterations)/(cycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "code_folding": [
     9,
     18
    ]
   },
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('my_keras_vanilla.h5',save_best_only=True)\n",
    "\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10,restore_best_weights=True)\n",
    "\n",
    "reduceLR_cb = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n",
    "                                                patience=5, min_lr=0.001)\n",
    "\n",
    "root_logdir = '/home/sayan/Documents/Bengali_Grapheme/logs/'\n",
    "\n",
    "def get_run_logdir(name):\n",
    "    import time\n",
    "    run_id = time.strftime(name)\n",
    "    return os.path.join(root_logdir,run_id)\n",
    "\n",
    "run_logdir = get_run_logdir('alexnet-run_%Y_%m_%d-%H_%M_%S')\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "\n",
    "cyclicLR_cb =  CyclicLR(base_lr=base_lr,\n",
    "                max_lr=max_lr,\n",
    "                step_size=step_size,\n",
    "                max_m=max_m,\n",
    "                base_m=base_m,\n",
    "                cyclical_momentum=cyclical_momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def model_vanilla():\n",
    "    \n",
    "    input_ = Input(shape=(64,64,1))\n",
    "    conv1 = Conv2D(filters=6, kernel_size=(3, 3), activation='relu')(input_)\n",
    "    avgpool1 = AvgPool2D()(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filters=16, kernel_size=(3, 3), activation='relu')(avgpool1)\n",
    "    avgpool2 = AvgPool2D()(conv2)\n",
    "\n",
    "    flat = Flatten()(avgpool2)\n",
    "    \n",
    "    dense_root_1 = Dense(2000,activation='relu')(flat)\n",
    "    dense_root_2 = Dense(1500,activation='relu')(dense_root_1)\n",
    "    dense_root_3 = Dense(1000,activation='relu')(dense_root_2)\n",
    "    dense_root_4 = Dense(800,activation='relu')(dense_root_3)\n",
    "    dense_root_5 = Dense(250,activation='relu')(dense_root_4)\n",
    "    output_root = Dense(168,activation='softmax')(dense_root_4)\n",
    "    \n",
    "    dense_vowel_1 = Dense(800,activation='relu')(flat)\n",
    "    dense_vowel_2 = Dense(600,activation='relu')(dense_vowel_1)\n",
    "    dense_vowel_3 = Dense(100,activation='relu')(dense_vowel_2)\n",
    "    output_vowel = Dense(11,activation='softmax')(dense_vowel_3)\n",
    "    \n",
    "    dense_consonant_1 = Dense(800,activation='relu')(flat)\n",
    "    dense_consonant_2 = Dense(600,activation='relu')(dense_consonant_1)\n",
    "    dense_consonant_3 = Dense(100,activation='relu')(dense_consonant_2)\n",
    "    output_consonant = Dense(7,activation='softmax')(dense_consonant_3)\n",
    "    \n",
    "    model = keras.Model(inputs=[input_],outputs=[output_root,output_vowel,output_consonant])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla = model_vanilla()\n",
    "keras.utils.plot_model(model_vanilla, '../results/vanilla_model.png', expand_nested=True, show_shapes=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vanilla.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.05),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_vanilla = model_vanilla.fit(train_gen_image,\n",
    "                                    validation_data=valid_gen_image,\n",
    "                                    epochs = 5,callbacks=[tensorboard_cb,reduceLR_cb,early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alex Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def model_alexnet():\n",
    "    \n",
    "    input_ = Input(shape=(64,64,1))\n",
    "    \n",
    "    conv1 = Conv2D(filters=96, kernel_size=(11, 11), strides=4, padding='valid', activation='relu')(input_)\n",
    "    maxpool1 = MaxPooling2D(pool_size=(3, 3), strides=2, padding='valid')(conv1)\n",
    "    \n",
    "    conv2 = Conv2D(filters=256, kernel_size=(5, 5), strides=1, padding='same', activation='relu')(maxpool1)\n",
    "    maxpool2 = MaxPooling2D(pool_size=(3, 3), strides=2, padding='valid')(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(maxpool2)\n",
    "    conv4 = Conv2D(filters=384, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(conv3)\n",
    "    conv5 = Conv2D(filters=256, kernel_size=(3, 3), strides=1, padding='same', activation='relu')(conv4)\n",
    "    \n",
    "    flat = Flatten()(conv5)\n",
    "    \n",
    "    dense_root_1 = Dense(4096,activation='relu')(flat)\n",
    "    dense_root_2 = Dense(4096,activation='relu')(dense_root_1)\n",
    "    dense_root_3 = Dense(1000,activation='relu')(dense_root_2)\n",
    "    output_root = Dense(168,activation='softmax')(dense_root_3)\n",
    "    \n",
    "    dense_vowel_1 = Dense(800,activation='relu')(flat)\n",
    "    dense_vowel_2 = Dense(600,activation='relu')(dense_vowel_1)\n",
    "    dense_vowel_3 = Dense(100,activation='relu')(dense_vowel_2)\n",
    "    output_vowel = Dense(11,activation='softmax')(dense_vowel_3)\n",
    "    \n",
    "    dense_consonant_1 = Dense(800,activation='relu')(flat)\n",
    "    dense_consonant_2 = Dense(600,activation='relu')(dense_consonant_1)\n",
    "    dense_consonant_3 = Dense(100,activation='relu')(dense_consonant_2)\n",
    "    output_consonant = Dense(7,activation='softmax')(dense_consonant_3)\n",
    "    \n",
    "    model = keras.Model(inputs=[input_],outputs=[output_root,output_vowel,output_consonant])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_alexnet = model_alexnet()\n",
    "keras.utils.plot_model(model_alexnet, '../results/vanilla_alexnet.png', expand_nested=True, show_shapes=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 1507 steps, validate for 503 steps\n",
      "Epoch 1/5\n",
      " 985/1507 [==================>...........] - ETA: 1:46 - loss: 47862550.8511 - dense_3_loss: 47200724.0000 - dense_7_loss: 410341.0625 - dense_11_loss: 251470.5469 - dense_3_accuracy: 0.0252 - dense_7_accuracy: 0.1879 - dense_11_accuracy: 0.6228"
     ]
    }
   ],
   "source": [
    "model_alexnet.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer = keras.optimizers.Adam(learning_rate=0.05),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_alexnet = model_alexnet.fit(train_gen_image,\n",
    "                                    validation_data=valid_gen_image,\n",
    "                                    epochs = 5,callbacks=[tensorboard_cb,reduceLR_cb,early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
